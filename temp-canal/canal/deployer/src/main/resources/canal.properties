# canal 远程mysql配置地址。用于覆盖本地canal.properties
#canal.manager.jdbc.url=jdbc:mysql://127.0.0.1:3306/canal_manager?useUnicode=true&characterEncoding=UTF-8
#canal.manager.jdbc.username=root
#canal.manager.jdbc.password=121212

#自动扫描conf目录下的实例配置纬度的文件。新增则启动新的实例，删除则停止老的实例
canal.auto.scan = false
canal.auto.scan.interval = 5
#当前服务启动的实例列表，非自动扫描时用的地址
canal.destinations = example
#实例的文件夹所在目录，文件夹需要与destinations指定的实例名相同，比如conf/ocsOrderKafka,每个实例文件夹下都有它的配置文件
canal.conf.dir = ../conf


# aliyun ak/sk , support rds/mq
# unknown
canal.aliyun.accessKey =
canal.aliyun.secretKey =



#服务器相关-------------------------------------------------------------------------

#id 本服务器的唯一编号 ip,canal server所在主机ip不填写则自动获取， port:canal服务器开放端口
canal.id = 2
canal.ip =
canal.port = 11113
# tcp, kafka, RocketMQ
canal.serverMode = kafka
canal.zkServers =127.0.0.1:2181

# 监控接口端口(配合Prometheus使用)
canal.metrics.pull.port = 11114
# canal持久化数据到zookeeper上的更新频率，单位毫秒
canal.zookeeper.flush.period = 1000
# 是否关闭server端的netty服务 false打开，true关闭
canal.withoutNetty = false






## 持久化、刷盘相关--------------------------------------------------------------------------
# canal 本地持久化的目录，一般为 /conf/instanceName.
# 搭配scan=true的时候使用，为动态读取的目录
canal.file.data.dir = ${canal.conf.dir}
# 持久化频率
canal.file.flush.period = 1000
## Canal的buffer大小，可缓存的buffer记录数，需要为2的指数
canal.instance.memory.buffer.size = 16384
## 内存记录的单位大小，默认1KB，和buffer.size组合决定最终的内存使用大小
canal.instance.memory.buffer.memunit = 1024
## canal内存store中数据缓存模式：
# 1. ITEMSIZE : 根据buffer.size进行限制，只限制记录的数量；
# 2. MEMSIZE : 根据buffer.size * buffer.memunit的大小，限制缓存记录的大小
canal.instance.memory.batch.mode = MEMSIZE
# 反序列化message用到属性
canal.instance.memory.rawEntry = true



## 检测通讯、相关配置--------------------------------------------------------------------------

# 是否打开心跳检测
canal.instance.detecting.enable = false
# 心跳检查sql
canal.instance.detecting.sql = select 1
# 心跳检测频率，单位为秒
canal.instance.detecting.interval.time = 3
# 心跳检测重试，重试3次，3次以上则认为失败
canal.instance.detecting.retry.threshold = 3
# 心跳检查失败后，是否开启自动mysql自动切换
# 说明：比如心跳检查失败超过阀值后，如果该配置为true，canal就会自动链到mysql备库获取binlog数据
canal.instance.detecting.heartbeatHaEnable = false


## mysql事务以及切换mysql回退binlog--------------------------------------------------------------------------

# 支持最大事务大小，超过事务大小将被切割成多个事务交付
canal.instance.transaction.size =  1024
# canal发生mysql切换时，在新的mysql库上查找binlog时需要往前查找的时间，单位秒
# 说明：mysql主备库可能存在解析延迟或者时钟不统一，需要回退一段时间，保证数据不丢
canal.instance.fallbackIntervalInSeconds = 60


## 网络链接相关配置--------------------------------------------------------------------------
canal.instance.network.receiveBufferSize = 16384
canal.instance.network.sendBufferSize = 16384
canal.instance.network.soTimeout = 30




## binlog 相关过滤器配置 --------------------------------------------------------------------------
canal.instance.filter.druid.ddl = true

# 是否忽略dcl语句，比如grant/create user等 false为不忽略，true为忽略
canal.instance.filter.query.dcl = false
# 是否忽略DML的query语句，比如insert/update/delete table.(mysql5.6的ROW模式可以包含statement模式的query记录) false为不忽略，true为忽略
canal.instance.filter.query.dml = false
# 是否忽略DDL的query语句，比如create table/alater table/drop table/rename table/create index/drop index. false为不忽略，true为忽略
canal.instance.filter.query.ddl = false
# 是否忽略binlog表结构获取失败的异常(主要解决回溯binlog对应表已被删除或表结构与binlog不一致的情况) false为不忽略，true为忽略
canal.instance.filter.table.error = false
# 用于仅订阅除rows以外的数据，行数据将会被过滤 false为不忽略，true为忽略
canal.instance.filter.rows = false
# 建议设置为false，不忽略事务的开始结束标记，
# 具体参考https://blog.csdn.net/CWeeYii/article/details/78536374 filterTransactionEntry
canal.instance.filter.transaction.entry = false



# binlog 的format格式与记录格式校验
# 可参考 https://www.cnblogs.com/gomysql/p/6155160.html
canal.instance.binlog.format = ROW,STATEMENT,MIXED
canal.instance.binlog.image = FULL,MINIMAL,NOBLOB
# ddl语句是否隔离发送，开启隔离可保证每次只返回发送一条ddl数据，不和其他dml语句混合返回.(otter ddl同步使用)
canal.instance.get.ddl.isolation = false




#并行解析相关配置 ------------------------------------------------------------------------------

# 	是否开启binlog并行解析模式
#(串行解析资源占用少,但性能有瓶颈, 并行解析可以提升近2.5倍+)
canal.instance.parser.parallel = true
# 并行线程数，默认为可用处理器数的60%。建议不超过Runtime.getRuntime().availableProcessors()
#canal.instance.parser.parallelThreadSize = 16
# 	binlog并行解析的异步ringbuffer队列(必须为2的指数)，
canal.instance.parser.parallelBufferSize = 256




#时序数据库 tsdb相关 ------------------------------------------------------------------------------
# 参考 https://www.bookstack.cn/read/canal/13.md#%E6%97%B6%E5%BA%8F%E8%A1%A8%E7%BB%93%E6%9E%84%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1
# table meta tsdb info
# 是否开启tablemeta的tsdb能力,tsdb 时序数据
canal.instance.tsdb.enable = true
# h2.mv.db 存放目录位置
canal.instance.tsdb.dir = ${canal.file.data.dir:../conf}/${canal.instance.destination:}
# jdbc url的配置 (h2的地址为默认值，如果是mysql需要自行定义)
canal.instance.tsdb.url = jdbc:h2:${canal.instance.tsdb.dir}/h2;CACHE_SIZE=1000;MODE=MYSQL;
# 	tsdb用户名
canal.instance.tsdb.dbUsername = canal
# 	tsdb密码
canal.instance.tsdb.dbPassword = canal
#  tsdb 表结构本地存储用来做重放相关的配置
# todo-zl 暂时没搞懂
canal.instance.tsdb.snapshot.interval = 24
canal.instance.tsdb.snapshot.expire = 360
canal.instance.tsdb.spring.xml = classpath:spring/tsdb/h2-tsdb.xml






#canal实例相关-----------------------------------------------------------------------------------------------

#实例加载方式，这里支持两种，spring&manager.
canal.instance.global.mode = spring
canal.instance.global.lazy = false
canal.instance.global.spring.xml = classpath:spring/default-instance.xml
#canal.instance.global.manager.address = 127.0.0.1:1099





# mq相关配置-----------------------------------------------------------------------------------------------
canal.mq.servers = 127.0.0.1:9092
canal.mq.retries = 3
canal.mq.batchSize = 16384
canal.mq.maxRequestSize = 1048576
canal.mq.lingerMs = 100
canal.mq.bufferMemory = 67108864
canal.mq.canalBatchSize = 10
canal.mq.canalGetTimeout = 100
# 是否分区，true表示分区，false表示单一分区。如果需要强顺序性，则需要设置为false，
# 但是这样带来也会有性能损耗。
canal.mq.flatMessage = true
canal.mq.compressionType = none
canal.mq.acks = all
# use transaction for kafka flatMessage batch produce
canal.mq.transaction = false
#canal.mq.properties. =
canal.mq.topic=
canal.mq.dynamicTopic=